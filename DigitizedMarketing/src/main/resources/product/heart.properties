process.heart=/spark/app-spark-sql-memory-query/heart.daemon
process.heart.beat=/spark/app-spark-sql-memory-query/process-sql-mem-query-heart-beat2
process.heart.beat.interval.ms=60000

crm.data.models.pool=/tmp/crm/digitized-marketing/spark-sql-memory-query/crm-data-models-pool
crm.data.models.output=/tmp/crm/digitized-marketing/spark-sql-memory-query/crm-data-model-output/danny-test
crm.data.model.history.exefailed=/tmp/crm/digitized-marketing/spark-sql-memory-query/crm-data-models-history/exefailed/
crm.data.model.history.exeokay=/tmp/crm/digitized-marketing/spark-sql-memory-query/crm-data-models-history/exeokay/
crm.data.model.history.model.error=/tmp/crm/digitized-marketing/spark-sql-memory-query/crm-data-models-history/error/
crm.data.model.history.model.ignored=/tmp/crm/digitized-marketing/spark-sql-memory-query/crm-data-models-history/ignored/

crm.hbase.table.conf.path=/home/hadoop/upload/conf/table_configs.xml
crm.hdfs.site.xml.path=/home/hadoop/app/hadoop/etc/hadoop/hdfs-site.xml

#df or rdd
crm.df.write.style=rdd

crm.up.model.job.hessian.url=http://10.112.5.223:8080/crm-server/hessian/upModelJobHessianService
crm.model.concurrency.num=3
crm.model.df.partition.size=100
#是否处理标签模型
crm.tag.model.enabled=false

#任务名称
sql.mem.query.app.name="Sql memory query task"
#yarn, yarn-client, yarn-cluster
sql.mem.query.app.startup.model=yarn
#失败重试次数, 默认2
sql.mem.query.failed.retry.times=1
#失败重试间隔，毫秒，默认60000
sql.mem.query.failed.retry.interval.ms=30000
#监听任务池的频次，单位毫秒, 默认100
sql.mem.query.model.pool.monitor.hz=100
#启动缓存数据，缓存数据耗时，默认false
sql.mem.query.datasource.init.cache=false
#
sql.mem.query.datasource.storage.level=MEMORY_AND_DISK


#es相关配置
es.nodes=10.200.2.67
es.port=9200
es.index.auto.create=tree
es.nodes.wan.only=true
